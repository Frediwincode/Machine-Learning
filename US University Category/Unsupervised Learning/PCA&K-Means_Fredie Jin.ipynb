{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RP-UWLMS0qML",
        "QzFBHtFHRBkH",
        "1-M5G2ryQRSe",
        "AGkXmgmNsFfo",
        "T8J9g4TFGCTj",
        "cDbFDeF2JFAe",
        "8qJdsy4_Mfd8",
        "7mV9LXUKJt95",
        "9DPdhTJ1J9Ix",
        "gZy303cNLHad",
        "K-nzeiXvm05T",
        "B9G1r1WtWftI",
        "JGIVx5DOXXoU",
        "M1axK8yxMb7k",
        "8GMz7Q6hNSeJ",
        "svtie6bdO-cs",
        "tBnvY3H2PlgN",
        "YvYHpn0KQ0nK",
        "APZ9UPmA8g5m"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frediwincode/Machine-Learning/blob/main/US%20University%20Category/Unsupervised%20Learning/PCA%26K-Means_Fredie%20Jin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-UWLMS0qML"
      },
      "source": [
        "## Installing Things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbtXaxl9XvIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b0581e-16e9-41c2-dcfa-0b4be9fd1927"
      },
      "source": [
        "# You are going to need to run this cell, restart the runtime after running this command,\n",
        "# then start over before you can run the code in this notebook.\n",
        "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz (96.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVhbDjn513OF"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib import dates\n",
        "from datetime import datetime\n",
        "import re\n",
        "import calendar\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, GaussianNB, MultinomialNB\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import jieba\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIga8B1D1xrX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "feef69d2-a719-4c4f-dfda-ca576aa0d7c7"
      },
      "source": [
        "!pip install textstat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (from textstat) (0.9.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzFBHtFHRBkH"
      },
      "source": [
        "# Instructions\n",
        "In prior years, I had students complete this assignment in two parts. In Part 1, they created a text data set; in Part 2, they applied the principles of text analysis to their data. For this asisgnment, I am providing a data set of tweets that are crosswalked to two labels: 1) labels_A, and 2) labels_B\n",
        "\n",
        "*   The feature is the text in the column titled, \"text.\"\n",
        "*   The label is the category labeled, \"labels_A.\" Label A categorizes whether the tweet was positive, neutral, or negative.\n",
        "\n",
        "\n",
        "The purpose of this assignment is to apply what we did in Week 11 notebook.\n",
        "Please do not reinvent the wheel. This assignment is lengthy, but the code is copy and paste.\n",
        "\n",
        "\n",
        "The goal of this assignment is:\n",
        "1.   To apply key concepts of text analysis  \n",
        "2.   To learn how to adapt code to solve your problem. In industry, you will rarely create code from scratch. People have mastered it and shared it with the world. Adapting code is a key skill.\n",
        "\n",
        "\n",
        "**For this assignment, I have embedded my \"cheat sheet\" notes within this notebook. It is show as \"#comment\" in green text.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#download data by running this code\n",
        "#https://drive.google.com/file/d/1gAbdQaJOhjqLIfubpvCjG399TroHGvsg/view?usp=sharing\n",
        "!gdown --id 1gAbdQaJOhjqLIfubpvCjG399TroHGvsg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0oA034UkUNI",
        "outputId": "ce01dd1a-3e20-4c1f-b509-418e2068dbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gAbdQaJOhjqLIfubpvCjG399TroHGvsg\n",
            "To: /content/training_labeled.csv\n",
            "\r  0% 0.00/30.2k [00:00<?, ?B/s]\r100% 30.2k/30.2k [00:00<00:00, 38.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-M5G2ryQRSe"
      },
      "source": [
        "# Task 2.1\n",
        "Divide your data into a training set and a test set made up of 20% of the data. If you have 200 rows, your training set should have 160 examples, and your test set should have 40 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxpGlAKXZuUg"
      },
      "source": [
        "# create dataframe for the dataset. I have started this for you but you will finish it. Uldimately, you want a data set that includes\n",
        "# the key variables -- mainly, the text, labels A, and labels B\n",
        "# HINT: please follow Week 11 notebook closely; do not forget to display the final dataframe you create\n",
        "df=pd.read_csv(\"training_labeled.csv\")\n",
        "df=df.drop('Unnamed: 0', axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the dataset to 80% train, 20% test.\n",
        "# i have just started you out by creating the training set; but you need to create a second ojbect for the remianing 20% for the test set\n",
        "# pleaes display the length of both data sets (training and test)\n",
        "df_training=df.sample(frac=0.8, random_state=333)\n"
      ],
      "metadata": {
        "id": "_NRdAYB2T8UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2ZEWAqydB47"
      },
      "source": [
        "# Task 2.1\n",
        "\n",
        "Use 10-fold cross-validation on your training set. Each fold should contain 8% of the original training data (if you had 200 rows originally and use an 80% training set, each fold for optimization will contain 16 examples).\n",
        "\n",
        "Optimize a machine learning classifier predicting `labels_A`, using features you extract from the microblog texts.\n",
        "\n",
        "Complete all **FIVE** of the following optimizations. Before my email is flooded, I  repeat: you are to complete all **FIVE** of the following optimizations. I know what the rubric says.\n",
        "\n",
        "   - a) Compare Naïve Bayes, Logistic Regression, and SVMs on a unigram feature space.\n",
        "   - b) Compare a unigram feature space with a feature space that also includes longer N-grams.\n",
        "   - i) For Naive Bayes, evaluate different implementations: ComplementNB, MultinomialNB, BernoulliNB\n",
        "   - j) For Support Vector Machines, evaluate different kernels including a polynomial kernel and a radial basis function kernel.\n",
        "   - k) For Logistic Regression, try L1 and L2 regularization, as well as unregularized features.\n",
        "\n",
        "Report the performance of your best-tuned model on the cross-validated training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is where you begin adapting code from before\n",
        "# HINT: useful functions from week 11 notebook.\n",
        "# You will call these functions for the following optimizations.\n"
      ],
      "metadata": {
        "id": "_1ZZHrYPVy_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGkXmgmNsFfo"
      },
      "source": [
        "#### **a) Compare Naïve Bayes, Logistic Regression, and SVMs on a unigram feature space.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcM0BnSubMfV"
      },
      "source": [
        "# consult the example notebook (week 11 python)\n",
        "# I identify where I provide partial code vs. full code\n",
        "\n",
        "# define X (full code)\n",
        "vocab_size = 1000\n",
        "# By default we can build a unigram model - capturing individual words only (partial code)\n",
        "vectorizer = CountVectorizer(max_features=vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this mirror week 11 (please use this)\n",
        "\n",
        "# Now lets make a DataFrame with our BOW model representations for each message (partial code)\n",
        "bow_df = pd.DataFrame(X.toarray())\n",
        "\n",
        "# Make the column names the words (partial code)\n",
        "for k, v in vectorizer.vocabulary_.items():\n",
        "\n",
        "# Add our Y labels to our DataFrame (no code provided; figure it out!)\n",
        "\n",
        "# Take a look at our DataFrame (no code provided; figure it out!)"
      ],
      "metadata": {
        "id": "qFRQx2xnZ_MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consult the example notebook (week 11 python)\n",
        "\n",
        "# Pick Classifiers to Compare (full code)\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifiers = {\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"Linear SVM\": LinearSVC(),\n",
        "    \"RBF SVM\": SVC(kernel='rbf'),\n",
        "    \"Poly SVM\": SVC(kernel='poly'),\n",
        "    \"Complement NB\": ComplementNB(),\n",
        "    \"Multinomial NB\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", multi_class='ovr', max_iter=10000, random_state=123),\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers (no code provided; figure it out!)\n",
        "\n",
        "# Choose a metric to optimize over (no code provided; figure it out!)\n",
        "\n",
        "# Pick features to use (remember, you have 3 labels in this assignment; not 4 like week 11 python script) (no code provided; figure it out!)\n",
        "\n",
        "# Compare models and display final result (no code provided; figure it out!)"
      ],
      "metadata": {
        "id": "R1mmnN5zaY9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLEASE WRITE UP IN ONE SENTENCE WHAT THE BEST MODEL WAS AND KAPPA VALUE**"
      ],
      "metadata": {
        "id": "niDi3rvxa1sQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sT8Xi5xbHO7"
      },
      "source": [
        "####**b) Compare a unigram feature space with a feature space that also includes longer N-grams.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a vocab of n-grams from the dataframe\n",
        "def ngrams(df, vocab_size = 1000, max_n=1):\n",
        "  vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=(1,max_n))\n",
        "  X = vectorizer.fit_transform(df[\"text\"])\n",
        "\n",
        "  bow_df = pd.DataFrame(X.toarray())\n",
        "  column_names = [str(i) for i in range(vocab_size)]\n",
        "  for k, v in vectorizer.vocabulary_.items():\n",
        "    column_names[v] = k\n",
        "  bow_df.columns = column_names\n",
        "\n",
        "  bow_df[\"labels_A\"] = df[\"labels_A\"].reset_index()['labels_A']\n",
        "  return bow_df\n",
        "# create unigram and bigrams DataFrame\n",
        "unigram_df = ngrams(df_training, max_n=1)\n",
        "bigram_df = ngrams(df_training, max_n=2)"
      ],
      "metadata": {
        "id": "ByF9alHvZ-ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consult the example notebook (week 11 python)\n",
        "# the goal is to compare the unigram to bigram (1 vs. 2)\n",
        "# you will use a logistic regression classfier\n",
        "\n",
        "# Pick Classifiers to Compare (full code)\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "classifiers = {\n",
        "     \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", multi_class='ovr', max_iter=10000, random_state=123)\n",
        "}\n",
        "\n",
        "### Compare classifiers on unigrams ###\n",
        "# Pick features to use (full code)\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result (no code provided; figure it out!)\n",
        "\n",
        "\n",
        "### Compare classifiers on bigrams ###\n",
        "# Pick features to use (full code)\n",
        "feature_set = list(bigram_df.columns[:-1])\n",
        "\n",
        "# Compare models and display final result (no code provided; figure it out!)"
      ],
      "metadata": {
        "id": "86XlIqzqbZDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLEASE WRITE UP IN ONE SENTENCE WHAT THE BEST MODEL WAS AND KAPPA VALUE**"
      ],
      "metadata": {
        "id": "1-1gz2Dta_0z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_XaF8IobHwa"
      },
      "source": [
        "#### **i) For Naive Bayes, evaluate different implementations: ComplementNB, MultinomialNB, BernoulliNB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNPYTLfZbI98"
      },
      "source": [
        "#insert code here\n",
        "\n",
        "# Pick Classifiers to Compare (no code provided; figure it out!)\n",
        "\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers (no code provided; figure it out!)\n",
        "\n",
        "\n",
        "# Choose a metric to optimize over (no code provided; figure it out!)\n",
        "\n",
        "\n",
        "# Pick features to use (full code)\n",
        "bow_features = column_names\n",
        "feature_set = bow_features\n",
        "\n",
        "# Compare models and display final result (no code provided; figure it out!)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLEASE WRITE UP IN ONE SENTENCE WHAT THE BEST MODEL WAS AND KAPPA VALUE**"
      ],
      "metadata": {
        "id": "_QOD_nNzbFVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **j) For Support Vector Machines, evaluate different kernels including a polynomial kernel and a radial basis function kernel.**"
      ],
      "metadata": {
        "id": "AGU83uTKXmGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick Classifiers to Compare (partial code)\n",
        "classifiers = {\n",
        "    \"Linear SVM\": ,\n",
        "    \"RBF SVM\": SVC(),\n",
        "    \"Poly SVM\": SVC()\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Choose a metric to optimize over (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Pick features to use (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Compare models and display final result (no code provided; this should be copy/paste at this point from above)"
      ],
      "metadata": {
        "id": "WqHmIgtDXrGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLEASE WRITE UP IN ONE SENTENCE WHAT THE BEST MODEL WAS AND KAPPA VALUE**"
      ],
      "metadata": {
        "id": "zinEtx9ZbGfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **k) For Logistic Regression, try L1 and L2 regularization, as well as unregularized features.**"
      ],
      "metadata": {
        "id": "1uxlz4clXrZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HINT 1: build 3 models using logistic regression\n",
        "# HINT 2; set max_iter=10000; solver='saga'; random_sate=123\n",
        "# HINT 3: the difference between L1 vs. L2 vs. \"regular\" logistic regression is in the penalty fuction\n",
        "# HINT 4: for regular, penalty=blank; for L2, penalty = l2; for L1, penalty = l1\n",
        "\n",
        "# Pick Classifiers to Compare (partial code provided to start you off)\n",
        "classifiers = {\n",
        "    \"LogisticRegression l2\": LogisticRegression(),\n",
        "    \"LogisticRegression l1\": LogisticRegression(),\n",
        "    \"Unregularized Features\": LogisticRegression()}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Choose a metric to optimize over (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Pick features to use (no code provided; this should be copy/paste at this point from above)\n",
        "\n",
        "\n",
        "# Compare models and display final result (no code provided; this should be copy/paste at this point from above)\n"
      ],
      "metadata": {
        "id": "_7FgyCQ0X_R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLEASE WRITE UP IN ONE SENTENCE WHAT THE BEST MODEL WAS AND KAPPA VALUE**"
      ],
      "metadata": {
        "id": "4UAbbEDMbHTo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOOkWEaIdEWu"
      },
      "source": [
        "# Task 2.3\n",
        "\n",
        "Train two models, each **trained on the full 80% training set, and tested on the held-out 20% test set**:\n",
        "   - A Naïve Bayes classifier with unigram features.\n",
        "   - The best-tuned model from task two, retrained on the full 80% training set.\n",
        "   \n",
        "Report three sets of evaluation metrics:\n",
        "   - The estimated performance from cross-validation in Task 2.\n",
        "   - The performance of the simple Naïve Bayes unigram classifier on the held-out test set.\n",
        "   - The performance of the best-tuned model on the held-out test set.\n",
        "\n",
        "At minimum, your evaluations should include percent accuracy and Kappa values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mV9LXUKJt95"
      },
      "source": [
        "####**A Naive Bayes classifier with unigram features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoLJJdubWyp"
      },
      "source": [
        "# Train a Naive Bayes classifier with unigram features.\n",
        "# choose BernoulliNB() as our Naive Bayes classifer.\n",
        "\n",
        "#set up unigram dataframe (for both test/training) (partial code provided)\n",
        "unigram_df=ngrams(df, max_n=1)\n",
        "feature_set = list(unigram_df.columns[:-1])\n",
        "unigram_training=unigram_df.iloc[df_training.index,:]\n",
        "unigram_testing=unigram_df.iloc[df_testing.index,:]\n",
        "\n",
        "#create your x_train,y_train,x_test,y_test (partial code provided)\n",
        "X_train=unigram_training.loc[:, feature_set]\n",
        "y_train=unigram_training.iloc[:,-1]\n",
        "\n",
        "#set BenroulliNB as your classifier (partial code provided)\n",
        "#Hint: you have to fit your x-train / y-train\n",
        "NB=BernoulliNB()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DPdhTJ1J9Ix"
      },
      "source": [
        "####**The best-tuned model from task two, retrained on the full 80% training set.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFaRfe2ObZql"
      },
      "source": [
        "# Train the best performance mode from part 1 of assignment (best trained = highest kappa)\n",
        "#Hint: build the model; then fit it using the x-train/y-train (same as above)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "\n",
        "#perform this for Naive Bayes classifier with unigram features.\n",
        "\n",
        "# Calculate and print the estimated performance from 10-fold-validation (partial code)\n",
        "a_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "\n",
        "\n",
        "                         )\n",
        "# print('10-fold accuracy: %s' % a_scores) (partial code)\n",
        "print(\"Estimated performance from cross-validation:\")\n",
        "print('10-fold accuracy: %.3f +/- %.3f' % (np.mean(a_scores), np.std(a_scores)))\n",
        "\n",
        "kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "k_scores = cross_val_score(estimator = NB,\n",
        "                         X = X_train,\n",
        "\n",
        "\n",
        "\n",
        "                         )\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores)  (full code)\n",
        "print('10-fold Kappa: %.3f +/- %.3f' % (np.mean(k_scores), np.std(k_scores)))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "# Calculate and print the performance of the Bernoulli NB model on the held-out test set (full code)\n",
        "print(\"Performance on the held-out test set:\")\n",
        "y_pred = NB.predict(X_test)\n",
        "accuracy_NB = accuracy_score(y_test, y_pred)\n",
        "print(f\"The accuracy is: {accuracy_NB:.4f}.\")\n",
        "kappa_NB = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"The Kappa is: {kappa_NB:.4f}.\")"
      ],
      "metadata": {
        "id": "YMk4Yfg7hVtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "\n",
        "#perform this for the best performance mode from part 1 of assignment (best trained = highest kappa)\n",
        "\n",
        "# Calculate and print the estimated performance from 10-fold-validation (same code as above)\n",
        "\n",
        "# print('10-fold accuracy: %s' % a_scores) (same code as above)\n",
        "\n",
        "# print('10-fold Cohen's Kappa: %s' % k_scores) (same code as above)\n",
        "\n",
        "# Calculate and print the performance of the Bernoulli NB model on the held-out test set. (same code as above)\n"
      ],
      "metadata": {
        "id": "fmLT89LqhV38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZy303cNLHad"
      },
      "source": [
        "####**Report three sets of evaluation metrics:**\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BlyTZVzLMXl"
      },
      "source": [
        "insert text answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2upx-ygRKE-"
      },
      "source": [
        "\n",
        "# Scoring Rubric\n",
        "![](https://drive.google.com/uc?export=view&id=1JqI8Tfmi3YrnjVdDxjwNu1ZOuOOgQCuI)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1VfVuKGmNBu6oJgXBTX4YB6Lxe_0t9cWN)"
      ]
    }
  ]
}